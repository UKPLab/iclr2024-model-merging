{
    "model_name_or_path": "roberta-base",
    "per_device_train_batch_size": 16,
    "per_device_eval_batch_size": 8,
    "gradient_accumulation_steps": 1,
    "cache_dir": TODO(),
    "max_input_length": 384,
    "max_output_length": 128,
    "optimizer_name": "AdamW",
    "warmup_steps": 100,
    "min_lr": 0.0,
    "dropout": 0.0,
    "max_grad_norm": 1.0,
    "method": "sequence_classification",
    "learning_rate": 1e-05,
    "output_dir": "roberta-base-imdb",
    "num_train_epochs": 1,
    "logging_strategy": "steps",
    "logging_steps": 128,
    "save_strategy": "epoch",
    "overwrite_output_dir": true,
    "evaluation_strategy": "epoch",
    "dataset_name": "/path/to/iclr2024-model-merging/code/merging/datasets/imdb.py",
    "dataset_config_name": "classification",
    "dataset_train_split": "train",
    "dataset_val_split": "validation"
}